{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-25T21:00:55.796172Z","iopub.execute_input":"2022-06-25T21:00:55.796918Z","iopub.status.idle":"2022-06-25T21:00:55.811140Z","shell.execute_reply.started":"2022-06-25T21:00:55.796871Z","shell.execute_reply":"2022-06-25T21:00:55.809214Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# #-------------------------------------------------#\n#     Topic American Express Default Prediction    \n# #-------------------------------------------------#\n\nGoal: We aims to build a robust model to predict default credit payement of client\n\nData Insights: \nThe data we use has 190 columns. it contains both categorical and Numerical values. \n\nThe following column name has categorical value and the remainder is Numerical \n\n['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68'].\n\nThe Numerical values are normalized \n\n","metadata":{}},{"cell_type":"markdown","source":"## Dependancies ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport missingno as mno","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:55:55.699878Z","iopub.execute_input":"2022-06-25T19:55:55.700447Z","iopub.status.idle":"2022-06-25T19:55:56.600212Z","shell.execute_reply.started":"2022-06-25T19:55:55.700398Z","shell.execute_reply":"2022-06-25T19:55:56.599144Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"X_train= pd.read_feather(\"../input/feather-datasets-amex-default-prediction/train_data.ftr\",columns=None, use_threads=True, storage_options=None)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:01:09.785032Z","iopub.execute_input":"2022-06-25T21:01:09.785495Z","iopub.status.idle":"2022-06-25T21:01:27.627841Z","shell.execute_reply.started":"2022-06-25T21:01:09.785460Z","shell.execute_reply":"2022-06-25T21:01:27.626902Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"Y_train=pd.read_csv(\"../input/amex-default-prediction/train_labels.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test=pd.read_feather(\"../input/feather-datasets-amex-default-prediction/test_data.ftr\",columns=None, use_threads=True, storage_options=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T10:35:37.814249Z","iopub.execute_input":"2022-06-25T10:35:37.815383Z","iopub.status.idle":"2022-06-25T10:36:14.290889Z","shell.execute_reply.started":"2022-06-25T10:35:37.815302Z","shell.execute_reply":"2022-06-25T10:36:14.289524Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Data insights","metadata":{}},{"cell_type":"code","source":"X_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:23:45.334125Z","iopub.execute_input":"2022-06-25T19:23:45.334912Z","iopub.status.idle":"2022-06-25T19:23:45.376802Z","shell.execute_reply.started":"2022-06-25T19:23:45.334862Z","shell.execute_reply":"2022-06-25T19:23:45.375462Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## List and chunk all columns according to their type","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import List \n\n\n@dataclass\nclass OutVerificator():\n    columnsWhereTypeObject : List[str]\n    columnsWhereTypeCategory : List[str]\n    columnsWhereFloat16 : List[str]\n    columnsWhereOther : List[str]\n      \n    \n\nclass typeVerificator():\n    def __init__(self):\n        pass\n    \n    def Verificator(self,df):\n        columnsWhereTypeObject=[list(df.columns)[columns_Index] for columns_Index in range(len(df.columns)) if str(list(df.dtypes)[columns_Index])==\"object\" ]\n        columnsWhereTypeCategory=[list(df.columns)[columns_Index] for columns_Index in range(len(df.columns)) if str(list(df.dtypes)[columns_Index])==\"category\" ]\n        columnsWhereFloat16=[list(df.columns)[columns_Index] for columns_Index in range(len(df.columns)) if str(list(df.dtypes)[columns_Index])=='float16' ]\n        columnsWhereOther=[ list(df.columns)[columns_Index] for columns_Index in range(len(df.columns)) if (str(list(df.dtypes)[columns_Index])!='float16' \n                                                            and str(list(df.dtypes)[columns_Index])!=\"category\" and str(list(df.dtypes)[columns_Index])!=\"object\")]\n        \n        return OutVerificator(columnsWhereTypeObject=columnsWhereTypeObject,\n                              columnsWhereTypeCategory=columnsWhereTypeCategory,\n                              columnsWhereFloat16=columnsWhereFloat16,\n                              columnsWhereOther=columnsWhereOther)\n        \n        \n        \n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:01:55.094034Z","iopub.execute_input":"2022-06-25T21:01:55.094541Z","iopub.status.idle":"2022-06-25T21:01:55.109151Z","shell.execute_reply.started":"2022-06-25T21:01:55.094492Z","shell.execute_reply":"2022-06-25T21:01:55.107928Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"parser=typeVerificator()\nResponse=parser.Verificator(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:02:04.499509Z","iopub.execute_input":"2022-06-25T21:02:04.499951Z","iopub.status.idle":"2022-06-25T21:02:04.615017Z","shell.execute_reply.started":"2022-06-25T21:02:04.499916Z","shell.execute_reply":"2022-06-25T21:02:04.613690Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#### If it not assertion Error it means that assertion is verified\nassert (len(Response.columnsWhereTypeObject)+len(Response.columnsWhereTypeCategory) + len (Response.columnsWhereFloat16) + len(Response.columnsWhereOther))==len(X_train.columns)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:02:06.689761Z","iopub.execute_input":"2022-06-25T21:02:06.690177Z","iopub.status.idle":"2022-06-25T21:02:06.695866Z","shell.execute_reply.started":"2022-06-25T21:02:06.690143Z","shell.execute_reply":"2022-06-25T21:02:06.694794Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"Response.columnsWhereTypeCategory","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:24:52.377370Z","iopub.execute_input":"2022-06-25T19:24:52.377833Z","iopub.status.idle":"2022-06-25T19:24:52.386027Z","shell.execute_reply.started":"2022-06-25T19:24:52.377796Z","shell.execute_reply":"2022-06-25T19:24:52.384729Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Categorical columns handling\nWe want to process the categorical columns by using a dummy variable and combining the result with the data recovery after removing the object columns. \n\n['D_63','D_64','D_66', 'D_68','B_30','B_38','D_114','D_116','D_117','D_120','D_126']","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nclass Categorical2Numerical():\n    \"\"\" \n    Convert categorical variable 2 Numerical using dummy variable\n    \"\"\"\n    def __init__(self,df):\n        parser=typeVerificator()\n        self.Response=parser.Verificator(df)\n        self.df=df\n        \n    def __str__(self):\n        return \"We aims to convert categorical variable 2 Numerical using dummy variable\"\n    \n    def categorical2numerical(self):\n        df=pd.get_dummies(self.df[self.Response.columnsWhereTypeCategory],dummy_na=True)\n        \n        scaler=MinMaxScaler()\n        scaled= scaler.fit_transform(df)\n        \n        return pd.DataFrame(scaled, columns=df.columns)\n        \n        \n        \n        \n     ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:02:22.818643Z","iopub.execute_input":"2022-06-25T21:02:22.820661Z","iopub.status.idle":"2022-06-25T21:02:23.952421Z","shell.execute_reply.started":"2022-06-25T21:02:22.820547Z","shell.execute_reply":"2022-06-25T21:02:23.950868Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"parser=Categorical2Numerical(X_train)\nparser.categorical2numerical()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:02:27.113842Z","iopub.execute_input":"2022-06-25T21:02:27.114898Z","iopub.status.idle":"2022-06-25T21:02:33.985845Z","shell.execute_reply.started":"2022-06-25T21:02:27.114851Z","shell.execute_reply":"2022-06-25T21:02:33.984571Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Merged the float, int and the last columns founded using dummy variable ","metadata":{}},{"cell_type":"code","source":"class Merging(Categorical2Numerical):\n    def __init__(self,df):\n        super().__init__(df)\n   \n    def __str__(self):\n        return \"Merge DataFrames\"\n    \n    def merging(self):\n \n        return pd.concat([self.df[ self.Response.columnsWhereFloat16],self.df[ self.Response.columnsWhereOther],self.categorical2numerical()], axis = 1) \n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:03:07.712051Z","iopub.execute_input":"2022-06-25T21:03:07.712566Z","iopub.status.idle":"2022-06-25T21:03:07.720360Z","shell.execute_reply.started":"2022-06-25T21:03:07.712526Z","shell.execute_reply":"2022-06-25T21:03:07.719258Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"parser=Merging(X_train)\nX_trainMerged=parser.merging()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:03:10.659754Z","iopub.execute_input":"2022-06-25T21:03:10.660486Z","iopub.status.idle":"2022-06-25T21:03:23.028018Z","shell.execute_reply.started":"2022-06-25T21:03:10.660446Z","shell.execute_reply":"2022-06-25T21:03:23.026716Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_trainMerged","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:03:25.710257Z","iopub.execute_input":"2022-06-25T21:03:25.710773Z","iopub.status.idle":"2022-06-25T21:03:26.952146Z","shell.execute_reply.started":"2022-06-25T21:03:25.710728Z","shell.execute_reply":"2022-06-25T21:03:26.951239Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## NaN values Processing","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass outNanSupervisor():\n    columnsNan : List[str]\n    columnsNotNan : List[str]\n        \n    \n\nclass NanSupervisor():\n    \"\"\"\n    This function takes a dataframe and returns an object of type list.\n    This object contains The names of the columns in which there is\n    Nan and The names of the columns in which there is not Nan.\n    \"\"\"\n    def __init__(self,df):\n        self.df=df\n    \n    def nansupervisor(self):\n        columnsNan=[column for column in list(self.df.columns) if self.df[column].isnull().sum()>0 ]\n        columnsNotNan=list(set(list(self.df.columns)).difference(set(columnsNan)))\n        \n        return outNanSupervisor(columnsNan=columnsNan,columnsNotNan=columnsNotNan)\n        \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:03:36.295372Z","iopub.execute_input":"2022-06-25T21:03:36.295809Z","iopub.status.idle":"2022-06-25T21:03:36.305875Z","shell.execute_reply.started":"2022-06-25T21:03:36.295772Z","shell.execute_reply":"2022-06-25T21:03:36.304544Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"parser=NanSupervisor(X_trainMerged)\nResponse=parser.nansupervisor()\nResponse.columnsNan","metadata":{"execution":{"iopub.status.busy":"2022-06-25T20:33:22.591730Z","iopub.execute_input":"2022-06-25T20:33:22.592163Z","iopub.status.idle":"2022-06-25T20:33:27.826967Z","shell.execute_reply.started":"2022-06-25T20:33:22.592114Z","shell.execute_reply":"2022-06-25T20:33:27.825881Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"mno.bar(X_trainMerged[['P_2','B_2','S_3','D_41','B_3','D_42','D_43','D_44','D_45','D_46']])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T20:10:12.518721Z","iopub.execute_input":"2022-06-25T20:10:12.519136Z","iopub.status.idle":"2022-06-25T20:10:13.705849Z","shell.execute_reply.started":"2022-06-25T20:10:12.519099Z","shell.execute_reply":"2022-06-25T20:10:13.704409Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"Response.columnsNotNan","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:41:01.131495Z","iopub.execute_input":"2022-06-25T19:41:01.131931Z","iopub.status.idle":"2022-06-25T19:41:01.142877Z","shell.execute_reply.started":"2022-06-25T19:41:01.131893Z","shell.execute_reply":"2022-06-25T19:41:01.141668Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"mno.bar(X_trainMerged[['D_63_CL','D_75','D_68_4.0','B_38_nan','B_9','B_30_1.0','R_3','D_68_2.0','D_58','R_6','B_14','S_20','D_64_O','D_68_5.0','R_22']],color=\"blue\")","metadata":{"execution":{"iopub.status.busy":"2022-06-25T20:11:46.585608Z","iopub.execute_input":"2022-06-25T20:11:46.586032Z","iopub.status.idle":"2022-06-25T20:11:47.935897Z","shell.execute_reply.started":"2022-06-25T20:11:46.585993Z","shell.execute_reply":"2022-06-25T20:11:47.934748Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"How i want to process the Nan values \n* D_* = Delinquency variables\n* S_* = Spend variables\n* P_* = Payment variables\n* B_* = Balance variables\n* R_* = Risk variables\n\nTo process the Nan inside the dataframe, I want to do it as follows:\n\n* D_* = Delinquency variables (Most frequence values)\n* S_* = Spend variables (Mean values)\n* P_* = Payment variables (Mean values)\n* B_* = Balance variables (Median values)\n* R_* = Risk variables (Mean values)","metadata":{}},{"cell_type":"code","source":"import re \nfrom  sklearn.impute import SimpleImputer\n    \nclass DataCleaner(NanSupervisor):\n    \"\"\"\n    This function Handling Nan values \n    and return the dataframe without Nan\n    \"\"\"\n    \n    def __init__(self,df):\n        super().__init__(df)\n    \n    def datacleaner(self):\n        \"chunking\"\n        Response=self.nansupervisor()\n        AllcolumnsNan=Response.columnsNan\n        DelinquencyNan=[columnDelinquency for columnDelinquency in AllcolumnsNan if re.search(\"D_\\d+\", columnDelinquency) ]\n        SpendNan=[columnSpend for columnSpend in AllcolumnsNan if re.search(\"S_\\d+\", columnSpend) ]\n        PaymentNan=[columnPayment for columnPayment in AllcolumnsNan if re.search(\"P_\\d+\", columnPayment) ]\n        BalanceNan=[columnBalance for columnBalance in AllcolumnsNan if re.search(\"B_\\d+\", columnBalance) ]\n        RiskNan=[columnRisk for columnRisk in AllcolumnsNan if re.search(\"R_\\d+\", columnRisk) ]\n        \n        assert (len(DelinquencyNan) + len(SpendNan) + len(PaymentNan) + len(BalanceNan) +len( RiskNan))==len(AllcolumnsNan)\n        \n        #if assertion error, review this function\n        # List columns Mean \n        SPR=list((set(SpendNan).union(PaymentNan)).union(set(RiskNan)))\n        \n        for columns in SPR:\n            self.df[columns].fillna(self.df[columns].mean(),inplace=True)\n#             parser=SimpleImputer(missing_values=0,strategy=\"mean\")\n#             self.df[columns]=parser.fit_transform(self.df[columns].values.reshape(len(self.df[columns]),1))\n            \n        # List columns Median\n        for columns in BalanceNan:\n            self.df[columns].fillna(self.df[columns].median(),inplace=True)\n#             parser=SimpleImputer(missing_values=0,strategy=\"median\")\n#             self.df[columns]=parser.fit_transform(self.df[columns].values.reshape(len(self.df[columns]),1))\n            \n        # List columns most_frequent \n        for columns in DelinquencyNan:\n            self.df[columns].fillna(self.df[columns].median(),inplace=True)\n#             parser=SimpleImputer(missing_values=0,strategy=\"most_frequent \")\n#             self.df[columns]=parser.fit_transform(self.df[columns].values.reshape(len(self.df[columns]),1))\n            \n        return self.df\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T23:47:07.231966Z","iopub.execute_input":"2022-06-25T23:47:07.233736Z","iopub.status.idle":"2022-06-25T23:47:07.254860Z","shell.execute_reply.started":"2022-06-25T23:47:07.233673Z","shell.execute_reply":"2022-06-25T23:47:07.253858Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"parser=DataCleaner(X_trainMerged)\nX_trainwithoutna=parser.datacleaner()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T23:47:10.453470Z","iopub.execute_input":"2022-06-25T23:47:10.453924Z","iopub.status.idle":"2022-06-25T23:47:33.448624Z","shell.execute_reply.started":"2022-06-25T23:47:10.453883Z","shell.execute_reply":"2022-06-25T23:47:33.447361Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"X_trainwithoutna","metadata":{"execution":{"iopub.status.busy":"2022-06-25T23:47:43.877617Z","iopub.execute_input":"2022-06-25T23:47:43.878045Z","iopub.status.idle":"2022-06-25T23:47:45.213614Z","shell.execute_reply.started":"2022-06-25T23:47:43.878009Z","shell.execute_reply":"2022-06-25T23:47:45.212355Z"},"trusted":true},"execution_count":86,"outputs":[]}]}